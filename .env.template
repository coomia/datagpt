###########################################################
#                   DATABASE CONFIG                      #
###########################################################
DB_DRIVER=postgresql
DB_HOST=postgres
DB_USER=postgres
DB_PASS=postgresql123
DB_PORT=5432
DB_NAME=datagpt

###########################################################
#                      CACHE CONFIG                       #
###########################################################
# Memory as default, Support Redis
# CACHE_TYPE=memory
# REDIS_HOST=redis
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=123456

###########################################################
#                      DB CONFIG                       #
###########################################################
#Support trino / postgresql / mysql / clickhouse / doris
SEARCH_DB_TYPE=postgresql
SEARCH_DB_HOST=postgres
SEARCH_DB_PORT=5432
SEARCH_DB_USER=postgres
SEARCH_DB_PASSWORD=postgresql123
SEARCH_DB_SCHEMA=public
SEARCH_DB_NAME=datagpt

###########################################################
#                  VECTOR DATABASE CONFIG                 #
###########################################################
# Default vector DB is pgvector (embedded in PostgreSQL)
# VECTOR_DB=pgvector
# VECTOR_COLLECTION=schema_info

# If you want to use Qdrant instead, uncomment and configure:
# VECTOR_DB=qdrant
# VECTOR_COLLECTION=schema_info
# QDRANT_HOST=qdrant
# QDRANT_PORT=6333

###########################################################
#                   EMBEDDING MODEL CONFIG                #
###########################################################
# Default embedding model is Ollama
EMBEDDING_MODEL_TYPE=ollama
EMBEDDING_MODEL_NAME=nomic-embed-text
EMBEDDING_MODEL_DIMENSIONS=768
OLLAMA_HOST=http://ollama-service:11434

# If you want to use OpenAI embeddings:
# EMBEDDING_MODEL_TYPE=openai
# EMBEDDING_MODEL_NAME=text-embedding-3-small
# OPENAI_API_KEY=your_openai_api_key

###########################################################
#                     LARGE LLM CONFIG                    #
###########################################################
# For OpenAI LLM (recommended for general users):
# MODEL_ID=gpt-4o-mini
# OPENAI_API_KEY=your_openai_api_key

# For Qwen / DashScope (enterprise users, fast inference in China):
MODEL_ID=qwen-flash-2025-07-28
DASHSCOPE_API_KEY=your_qwen_api_key

# For Deepseek (heavy analytics, slower but capable):
# MODEL_ID=deepseek-chat
# DEEPSEEK_API_KEY=your_deepseek_api_key

# For KIMI / Moonshot models:
# MODEL_ID=moonshot-v1-32k
# MOONSHOT_API_KEY=your_moonshot_api_key

###########################################################
#                      NOTES & RECOMMENDATIONS           #
###########################################################
# 1. Users in China may prefer Qwen or KIMI for lower latency.
# 2. Users with OpenAI accounts are recommended to use OpenAI embeddings 
#    (text-embedding-3-small) and LLM gpt-4o-mini or gpt-4o for balance of speed and quality.
# 3. To switch vector DB to Qdrant, configure VECTOR_DB and QDRANT_HOST/PORT accordingly.
# 4. Keep all API keys and credentials secret; do NOT commit them to Git.
